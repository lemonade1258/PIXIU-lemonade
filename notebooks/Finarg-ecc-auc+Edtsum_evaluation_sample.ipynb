{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaE1Pj3KXQSj"
   },
   "source": [
    "# **How to Use Colab Pro to Do Evaluations!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "307fcc28"
   },
   "source": [
    "**We suggest to use Colab pro's A100 GPU to do the evaluations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cS0GtlOYJh4"
   },
   "source": [
    "**Important: When you run, make sure you choose runtime A100 GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3E8BvAE5GEM"
   },
   "source": [
    "Git and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uYf2Zhg65I_9",
    "outputId": "8933cf15-4715-4fbb-8917-97fbc8c919e8"
   },
   "source": [
    "!git clone https://github.com/The-FinAI/PIXIU --recursive\n",
    "%cd PIXIU\n",
    "!pip install -r requirements.txt\n",
    "%cd /content/PIXIU/src/financial-evaluation\n",
    "!pip install -e .[multilingual]\n",
    "!pip install bert_score\n",
    "!pip install vllm==0.2.7"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fosY1vFA5N5E"
   },
   "source": [
    "Follow the Readme page download BART checkpoint to src/metrics/BARTScore/\n",
    "\n",
    "you can put bart_score.pth*bart_score.pth* file under your Google drive, connect drive to upload *bart_score.pth* to colab PIXIU folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zaw9s5xY5OaU",
    "outputId": "34eb83a7-3538-4fdd-a09c-7ffd6069c812"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!cp \"/content/drive/My Drive/bart_score.pth\" \"/content/PIXIU/src/metrics/BARTScore/bart_score.pth\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZO0tRdY5TqQ"
   },
   "source": [
    "When doing *bart score* related evaluation, you need to modify the code manually.\n",
    "\n",
    "Click *folder* on the left.\n",
    "\n",
    "/content/PIXIU/src/tasks/flare.py\n",
    "\n",
    "row 374 and 513\n",
    "\n",
    "bart_scorer.load(path=\"src/metrics/BARTScore/bart_score.pth\")\n",
    "\n",
    "change to\n",
    "\n",
    "bart_scorer.load(path=\"/content/PIXIU/src/metrics/BARTScore/bart_score.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPovkuRT5VA4",
    "outputId": "d224d8e0-90f3-4383-faf6-76fb9afa4a3d"
   },
   "source": [
    "%cd /content/PIXIU/src"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "887p63C-5XLJ"
   },
   "source": [
    "Modify the scrpits when you evaluate.\n",
    "\n",
    "e.g.\n",
    "\n",
    "pretrained=ChanceFocus/finma-7b-full,tokenizer=ChanceFocus/finma-7b-full\n",
    "\n",
    "pretrained=tiiuae/falcon-7b,tokenizer=tiiuae/falcon-7b\n",
    "\n",
    "you can find all the models on huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfC9ZiWX5pVo"
   },
   "source": [
    "Finarg_ecc_auc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-7TMcMF5rRe",
    "outputId": "fd62a793-d8b1-499b-f354-c375e8cac87b"
   },
   "source": [
    "!python eval.py \\\n",
    "    --model \"hf-causal-vllm\" \\\n",
    "    --model_args \"use_accelerate=True,pretrained=TheFinAI/finma-7b-full,tokenizer=TheFinAI/finma-7b-full,use_fast=False,max_gen_toks=20,dtype=float16\" \\\n",
    "    --tasks \"flare_finarg_ecc_auc\" \\\n",
    "    --batch_size 30000"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwvpmFmq6UJd"
   },
   "source": [
    "Edtsum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnA_R4t96pFs"
   },
   "source": [
    "!python eval.py \\\n",
    "    --model \"hf-causal-vllm\" \\\n",
    "    --model_args \"use_accelerate=True,pretrained=TheFinAI/finma-7b-full,tokenizer=TheFinAI/finma-7b-full,max_gen_toks=128,dtype=float16\" \\\n",
    "    --tasks \"flare_edtsum\" \\\n",
    "    --batch_size 30000"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
